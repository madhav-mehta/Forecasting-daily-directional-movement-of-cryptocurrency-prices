{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9647bd4a",
   "metadata": {},
   "source": [
    "# Reddit Scaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1677cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4b6c4",
   "metadata": {},
   "source": [
    "Personal credentials for reddit API, removed for privacy reasons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"_____________\",      \n",
    "    client_secret=\"______________\",  \n",
    "    user_agent=\"_______________\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5edeada",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COINS = {\n",
    "    'BTC': {\n",
    "        'search_terms': '(bitcoin OR btc)',\n",
    "        'subreddits': ['CryptoCurrency', 'Bitcoin', 'BitcoinMarkets', 'btc', 'CryptoMarkets']\n",
    "    },\n",
    "    'ETH': {\n",
    "        'search_terms': '(ethereum OR eth)',\n",
    "        'subreddits': ['CryptoCurrency', 'ethereum', 'ethtrader', 'CryptoMarkets']\n",
    "    },\n",
    "    'XRP': {\n",
    "        'search_terms': '(xrp OR ripple)',\n",
    "        'subreddits': ['CryptoCurrency', 'Ripple', 'XRP', 'CryptoMarkets']\n",
    "    }\n",
    "}\n",
    "TOPIC_KEYWORDS = '(price OR sentiment OR bull OR bear OR prediction OR analysis OR value OR news OR bullish OR bearish OR volume OR engagement OR liquidation OR liquidity OR Trump)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148efe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scrape for BTC\n",
      "\n",
      "Searching in subreddit: r/CryptoCurrency\n",
      "Found and processed 249 posts in r/CryptoCurrency.\n",
      "\n",
      "Searching in subreddit: r/Bitcoin\n",
      "Found and processed 244 posts in r/Bitcoin.\n",
      "\n",
      "Searching in subreddit: r/BitcoinMarkets\n",
      "Found and processed 95 posts in r/BitcoinMarkets.\n",
      "\n",
      "Searching in subreddit: r/btc\n",
      "Found and processed 248 posts in r/btc.\n",
      "\n",
      "Searching in subreddit: r/CryptoMarkets\n",
      "Found and processed 240 posts in r/CryptoMarkets.\n",
      "\n",
      " Successfully saved 12759 unique items for BTC.\n",
      "Starting scrape for ETH\n",
      "\n",
      "Searching in subreddit: r/CryptoCurrency\n",
      "Found and processed 247 posts in r/CryptoCurrency.\n",
      "\n",
      "Searching in subreddit: r/ethereum\n",
      "Found and processed 250 posts in r/ethereum.\n",
      "\n",
      "Searching in subreddit: r/ethtrader\n",
      "Found and processed 242 posts in r/ethtrader.\n",
      "\n",
      "Searching in subreddit: r/CryptoMarkets\n",
      "Found and processed 241 posts in r/CryptoMarkets.\n",
      "\n",
      " Successfully saved 13847 unique items for ETH.\n",
      "Starting scrape for XRP\n",
      "\n",
      "Searching in subreddit: r/CryptoCurrency\n",
      "Found and processed 247 posts in r/CryptoCurrency.\n",
      "\n",
      "Searching in subreddit: r/Ripple\n",
      "Found and processed 122 posts in r/Ripple.\n",
      "\n",
      "Searching in subreddit: r/XRP\n",
      "Found and processed 238 posts in r/XRP.\n",
      "\n",
      "Searching in subreddit: r/CryptoMarkets\n",
      "Found and processed 242 posts in r/CryptoMarkets.\n",
      "\n",
      " Successfully saved 11877 unique items for XRP.\n"
     ]
    }
   ],
   "source": [
    "POST_LIMIT = 1000\n",
    "COMMENT_LIMIT = 15\n",
    "\n",
    "def scrape_for_coin(coin_ticker, config):\n",
    "    print(f\"Starting scrape for {coin_ticker}\")\n",
    "    \n",
    "    scraped_data = []\n",
    "    processed_post_ids = set() \n",
    "    \n",
    "    # Constructing search query\n",
    "    search_query = f\"{config['search_terms']} AND {TOPIC_KEYWORDS}\"\n",
    "\n",
    "    # Looping through sub-reddits\n",
    "    for subreddit_name in config['subreddits']:\n",
    "        try:\n",
    "            subreddit = reddit.subreddit(subreddit_name)\n",
    "            print(f\"\\nSearching in subreddit: r/{subreddit_name}\")\n",
    "\n",
    "            search_results = subreddit.search(search_query, sort='relevance', time_filter='year', limit=POST_LIMIT)\n",
    "\n",
    "            post_count = 0\n",
    "            for post in search_results:\n",
    "                if post.id in processed_post_ids:\n",
    "                    continue\n",
    "                \n",
    "                post_count += 1\n",
    "                processed_post_ids.add(post.id)\n",
    "\n",
    "                scraped_data.append({\n",
    "                    'coin': coin_ticker,\n",
    "                    'date': datetime.datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d'),\n",
    "                    'type': 'post',\n",
    "                    'subreddit': subreddit_name,\n",
    "                    'title': post.title,\n",
    "                    'body': post.selftext,\n",
    "                    'score': post.score\n",
    "                })\n",
    "\n",
    "                post.comments.replace_more(limit=0) \n",
    "                comment_count = 0\n",
    "                for comment in post.comments.list():\n",
    "                    if comment_count >= COMMENT_LIMIT:\n",
    "                        break\n",
    "                    \n",
    "                    scraped_data.append({\n",
    "                        'coin': coin_ticker,\n",
    "                        'date': datetime.datetime.utcfromtimestamp(comment.created_utc).strftime('%Y-%m-%d'),\n",
    "                        'type': 'comment',\n",
    "                        'subreddit': subreddit_name,\n",
    "                        'title': f\"Comment on: {post.title[:50]}...\",\n",
    "                        'body': comment.body,\n",
    "                        'score': comment.score\n",
    "                    })\n",
    "                    comment_count += 1\n",
    "            \n",
    "            print(f\"Found and processed {post_count} posts in r/{subreddit_name}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" An error occurred while scraping r/{subreddit_name}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    if not scraped_data:\n",
    "        print(f\"\\nNo data found for {coin_ticker} with the current criteria.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(scraped_data)\n",
    "    df.drop_duplicates(subset=['body', 'title'], inplace=True)\n",
    "\n",
    "    file_name = f\"reddit_data_{coin_ticker}_24_25.csv\"\n",
    "    file_path = os.path.join(r'C:\\Users\\madha\\Desktop\\Dissertation\\Data\\Reddit API', file_name)\n",
    "    \n",
    "    df.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n Successfully saved {len(df)} unique items for {coin_ticker}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    for ticker, coin_config in TARGET_COINS.items():\n",
    "        scrape_for_coin(ticker, coin_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
